# loss 참고
https://github.com/rantsandruse/pytorch_lstm_01intro/blob/main/main_example.py  
functional loss : https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html
nll loss: https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html
# sigmoid cross entopy?!
* https://glassboxmedicine.com/2019/12/07/connections-log-likelihood-cross-entropy-kl-divergence-logistic-regression-and-neural-networks/

# softmax와 negative log lokelihood
https://airsbigdata.tistory.com/202
https://discuss.pytorch.org/t/what-happens-when-loss-are-negative/47883/4

# transpose, permute
https://sanghyu.tistory.com/3

# LSTM
lstm source code : https://github.com/simon-benigeri/lstm-language-model/blob/2f1f3ead89a9a088a676af6cd78723857aedbd2a/pipelines/datasets.py#L86
https://github.com/salesforce/awd-lstm-lm/blob/master/model.py
lstm hidden과 out 차이 : https://stackoverflow.com/questions/48302810/whats-the-difference-between-hidden-and-output-in-pytorch-lstm
bptt imple : https://stackoverflow.com/questions/65175252/truncated-bptt-pytorch-implementation-question

# cnn, lstm 구현
https://justkode.kr/deep-learning/pytorch-rnn